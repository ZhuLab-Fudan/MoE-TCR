logdir: ./log

model_cls: tecc
model_config:
  emb_size: 20
  dropout: 0.6
  hidden_size: 64

train:
  seed: 42
  batch_size: 64
  epochs: 200

  optimizer: Adam
  optimizer_config:
    lr: 0.0001
  checkpoint_monitor: val_auc01 
  checkpoint_monitor_mode: max 
  earlystop_patience: 80

  scheduler: ReduceLROnPlateau
  scheduler_config:
    mode: min
    factor: 0.1
    patience: 20
    verbose: True
    min_lr: 1.0e-6
  scheduler_monitor: val_loss 


bind_dataset:
  train_data: ./data/IMMREP22/train_redundancy_reduced_set.csv
  val_data: ./data/IMMREP22/train_redundancy_reduced_set.csv
  test_data: ./data/IMMREP22/test_set.csv
  esm_model: esm2_t30_150M_UR50D 
  esm_alphabet: ESM-1b
  sample_weight_dict: weight
  peptide_len: 12
  A1_len: 7
  A2_len: 8
  A3_len: 22
  B1_len: 6
  B2_len: 7
  B3_len: 23


